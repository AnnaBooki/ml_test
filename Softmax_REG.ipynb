{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aim: Predict if PM concentration is higher than boundary value based on meteorologic parameters, leave out influence of traffic data.\n",
    "daily boundary value for PM10:  50 µg/m³"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "#import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Load PM dataset (target var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        P1\n",
      "timestamp                 \n",
      "2020-01-23 00:02:21  57.70\n",
      "2020-01-23 00:04:57  58.93\n",
      "2020-01-23 00:07:26  60.67\n",
      "2020-01-23 00:10:05  58.90\n",
      "2020-01-23 00:13:07  57.97\n",
      "...                    ...\n",
      "2020-01-23 23:47:57  31.97\n",
      "2020-01-23 23:50:30  38.50\n",
      "2020-01-23 23:53:15  36.90\n",
      "2020-01-23 23:56:03  40.73\n",
      "2020-01-23 23:58:32  36.67\n",
      "\n",
      "[555 rows x 1 columns]\n",
      "                  P1\n",
      "timestamp           \n",
      "0          61.175455\n",
      "1          60.337778\n",
      "2          60.901000\n",
      "3          58.587727\n",
      "4          53.806000\n",
      "5          42.638333\n",
      "6          42.976667\n",
      "7          45.372917\n",
      "8          43.117500\n",
      "9          46.309130\n",
      "10         38.529583\n",
      "11         33.917500\n",
      "12         31.267083\n",
      "13         28.494000\n",
      "14         26.772917\n",
      "15         25.041667\n",
      "16         23.417917\n",
      "17         32.340417\n",
      "18         42.986818\n",
      "19         40.723913\n",
      "20         43.877083\n",
      "21         47.411250\n",
      "22         48.723333\n",
      "23         38.984737\n"
     ]
    }
   ],
   "source": [
    "os.chdir(r\"C:\\Users\\Anna\\Documents\\UNI\\MA Semi 1\\Machine Learning\\Final_project\")\n",
    "\n",
    "## test file from luftdateninfo\n",
    "file_pm = \"test_PM_2020-01-23_sds011_sensor_10963.csv\"\n",
    "pm_ds = pd.read_csv(file_pm, sep=\";\", index_col=\"timestamp\")\n",
    "\n",
    "## df with time_col as index\n",
    "pm_ds = pm_ds[[\"P1\"]]\n",
    "\n",
    "#Sum up to hourly values\n",
    "pm_ds.index = pd.to_datetime(pm_ds.index) # convert index into time_dtype\n",
    "print(pm_ds)\n",
    "\n",
    "###### needs to be chnaged- save timestamp  #########\n",
    "pm_ds_hour = pm_ds.groupby(pm_ds.index.hour).mean()# ds= one day -->24 rows\n",
    "print(pm_ds_hour)\n",
    "\n",
    "\n",
    "#pm_ds_hour.index = pd.to_datetime(pm_ds_hour.index, format=\"%Y-%m-%d %H:%M:%S\")#, unit=\"h\")\n",
    "pm_ds_hour.index = pd.to_datetime(pm_ds_hour.index,unit=\"h\")\n",
    "print(pm_ds_hour)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load meteorologic test-file and merge both ds (PM + meteo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              F    D   R1     P0  TT_TU  RF_TU\n",
      "MESS_DATUM                                    \n",
      "1995100414  2.6  220  0.0  970.6   23.3   51.0\n",
      "1995100415  3.6  210  0.0  970.3   23.8   50.0\n",
      "1995100416  1.5  150  0.0  969.9   23.0   54.0\n",
      "1995100417  1.5  120  0.0  970.0   21.5   63.0\n",
      "1995100418  1.5  180  0.0  970.1   19.4   71.0\n",
      "...         ...  ...  ...    ...    ...    ...\n",
      "2019123119  1.3  270  0.0  987.3    0.3   82.0\n",
      "2019123120  0.9  270  0.0  987.8    0.9   84.0\n",
      "2019123121  1.0  230  0.0  987.2    1.2   87.0\n",
      "2019123122  0.9  300  0.0  987.5    1.4   87.0\n",
      "2019123123  0.5  230  0.0  987.3    1.1   89.0\n",
      "\n",
      "[211931 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "file_wind =  pd.read_csv(\"./DWDstats_meteo/produkt_ff_stunde_19530101_20191231_04931.txt\", sep=\";\", header=0,\n",
    "                         index_col=\"MESS_DATUM\")\n",
    "#print(file_wind)\n",
    "file_rain = pd.read_csv(\"./DWDstats_meteo/produkt_rr_stunde_19951004_20191231_04931.txt\", sep=\";\", header=0,\n",
    "                         index_col=\"MESS_DATUM\")\n",
    "file_pressure = pd.read_csv(\"./DWDstats_meteo/produkt_p0_stunde_19490101_20191231_04931.txt\", sep=\";\", header=0,\n",
    "                          index_col=\"MESS_DATUM\") \n",
    "file_temperature = pd.read_csv(\"./DWDstats_meteo/produkt_tu_stunde_19880101_20191231_04931.txt\", sep=\";\", header=0,\n",
    "                          index_col=\"MESS_DATUM\") \n",
    "\n",
    "allmeteo = file_wind.merge(file_rain, on =\"MESS_DATUM\").merge(file_pressure, on =\"MESS_DATUM\").merge(file_temperature, on =\"MESS_DATUM\")\n",
    "allmeteo = allmeteo[[\"   F\", \"   D\", \"  R1\", \"  P0\", \"TT_TU\", \"RF_TU\"]]\n",
    "allmeteo = allmeteo.rename(columns={\"   F\": \"F\", \"   D\":\"D\", \"  R1\": \"R1\", \"  P0\": \"P0\"})\n",
    "\n",
    "print(allmeteo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.indexes.datetimes.DatetimeIndex'>\n",
      "DatetimeIndex(['1995-10-04 14:00:00', '1995-10-04 15:00:00',\n",
      "               '1995-10-04 16:00:00', '1995-10-04 17:00:00',\n",
      "               '1995-10-04 18:00:00', '1995-10-04 19:00:00',\n",
      "               '1995-10-04 20:00:00', '1995-10-04 21:00:00',\n",
      "               '1995-10-04 22:00:00', '1995-10-04 23:00:00',\n",
      "               ...\n",
      "               '2019-12-31 14:00:00', '2019-12-31 15:00:00',\n",
      "               '2019-12-31 16:00:00', '2019-12-31 17:00:00',\n",
      "               '2019-12-31 18:00:00', '2019-12-31 19:00:00',\n",
      "               '2019-12-31 20:00:00', '2019-12-31 21:00:00',\n",
      "               '2019-12-31 22:00:00', '2019-12-31 23:00:00'],\n",
      "              dtype='datetime64[ns]', name='MESS_DATUM', length=211931, freq=None)\n",
      "Empty DataFrame\n",
      "Columns: [P1, F, D, R1, P0, TT_TU, RF_TU]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## convert to same datetime\n",
    "allmeteo.index = pd.to_datetime(allmeteo.index, format=\"%Y%m%d%H\") # errors='ignore')\n",
    "print(type(pm_ds_hour.index))\n",
    "\n",
    "allmeteo2_hour = allmeteo2 #allmeteo2.groupby(allmeteo2.index.hour).mean()# ds= one day -->24 rows\n",
    "allmeteo2_hour.index = pd.to_datetime(allmeteo2_hour.index, unit=\"h\")\n",
    "print(allmeteo2_hour.index)\n",
    "\n",
    "\n",
    "# ### merge both DS (meteo Ds + PM DS)\n",
    "# print(type(allmeteo.index))\n",
    "PM_meteo = pm_ds_hour.merge(allmeteo, left_index = True, right_index=True) \n",
    "print(PM_meteo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F</th>\n",
       "      <th>D</th>\n",
       "      <th>R1</th>\n",
       "      <th>P0</th>\n",
       "      <th>TT_TU</th>\n",
       "      <th>RF_TU</th>\n",
       "      <th>P1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MESS_DATUM</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995-10-04 14:00:00</th>\n",
       "      <td>2.6</td>\n",
       "      <td>220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>970.6</td>\n",
       "      <td>23.3</td>\n",
       "      <td>51.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-10-04 15:00:00</th>\n",
       "      <td>3.6</td>\n",
       "      <td>210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>970.3</td>\n",
       "      <td>23.8</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-10-04 16:00:00</th>\n",
       "      <td>1.5</td>\n",
       "      <td>150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>969.9</td>\n",
       "      <td>23.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-10-04 17:00:00</th>\n",
       "      <td>1.5</td>\n",
       "      <td>120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>970.0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>63.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-10-04 18:00:00</th>\n",
       "      <td>1.5</td>\n",
       "      <td>180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>970.1</td>\n",
       "      <td>19.4</td>\n",
       "      <td>71.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 19:00:00</th>\n",
       "      <td>1.3</td>\n",
       "      <td>270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>987.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 20:00:00</th>\n",
       "      <td>0.9</td>\n",
       "      <td>270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>987.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>84.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 21:00:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>987.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 22:00:00</th>\n",
       "      <td>0.9</td>\n",
       "      <td>300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>987.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31 23:00:00</th>\n",
       "      <td>0.5</td>\n",
       "      <td>230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>987.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>211931 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       F    D   R1     P0  TT_TU  RF_TU  P1\n",
       "MESS_DATUM                                                 \n",
       "1995-10-04 14:00:00  2.6  220  0.0  970.6   23.3   51.0   3\n",
       "1995-10-04 15:00:00  3.6  210  0.0  970.3   23.8   50.0   4\n",
       "1995-10-04 16:00:00  1.5  150  0.0  969.9   23.0   54.0   2\n",
       "1995-10-04 17:00:00  1.5  120  0.0  970.0   21.5   63.0   4\n",
       "1995-10-04 18:00:00  1.5  180  0.0  970.1   19.4   71.0   4\n",
       "...                  ...  ...  ...    ...    ...    ...  ..\n",
       "2019-12-31 19:00:00  1.3  270  0.0  987.3    0.3   82.0   1\n",
       "2019-12-31 20:00:00  0.9  270  0.0  987.8    0.9   84.0   4\n",
       "2019-12-31 21:00:00  1.0  230  0.0  987.2    1.2   87.0   2\n",
       "2019-12-31 22:00:00  0.9  300  0.0  987.5    1.4   87.0   2\n",
       "2019-12-31 23:00:00  0.5  230  0.0  987.3    1.1   89.0   1\n",
       "\n",
       "[211931 rows x 7 columns]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## vorläufig\n",
    "PM_meteo = allmeteo\n",
    "PM_meteo[\"P1\"] = np.random.randint(0, 5, PM_meteo.shape[0])\n",
    "PM_meteo"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Split Dataset in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169544, 6)\n",
      "(169544,)\n",
      "(42387, 6)\n",
      "(42387,)\n"
     ]
    }
   ],
   "source": [
    "# split the boston hoursing dataset into training and testing \n",
    "x = PM_meteo[[\"F\", \"D\",\"R1\", \"P0\", \"TT_TU\", \"RF_TU\"]]#.values\n",
    "y = PM_meteo[\"P1\"]#.values\n",
    "\n",
    "\n",
    "ratio = 0.2 # split ratio\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=ratio,random_state=5)\n",
    "\n",
    "#print the size of train and test dataset\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " Use Softmax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "Xstan = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataStan=pd.DataFrame(data = Xstan, columns = PM_meteo.columns[0:6]) #[\"F\", \"D\",\"R1\", \"P0\", \"TT_TU\", \"RF_TU\"]])\n",
    "dataStan[\"P1\"]=y\n",
    "dataStan.head()\n",
    "\n",
    "softReg = LogisticRegression(multi_class = 'multinomial', solver = 'lbfgs')\n",
    "softReg.fit(Xstan,y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.00256376,  0.00679844, -0.00910539, -0.00051189,  0.0053826 ]),\n",
       " array([[-0.00473569,  0.00073119, -0.00072512,  0.00176374,  0.00186578,\n",
       "         -0.00044391],\n",
       "        [-0.00061064,  0.00389722, -0.00165798,  0.00476586,  0.00238907,\n",
       "         -0.00118316],\n",
       "        [ 0.00334544,  0.00416248,  0.00714612, -0.00476839, -0.00332466,\n",
       "          0.00537091],\n",
       "        [-0.00206968, -0.00843612, -0.00022594,  0.00115601, -0.00239714,\n",
       "          0.00050719],\n",
       "        [ 0.00407058, -0.00035477, -0.00453707, -0.00291723,  0.00146695,\n",
       "         -0.00425103]]))"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softReg.intercept_, softReg.coef_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F</th>\n",
       "      <th>D</th>\n",
       "      <th>R1</th>\n",
       "      <th>P0</th>\n",
       "      <th>TT_TU</th>\n",
       "      <th>RF_TU</th>\n",
       "      <th>P1</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.025015</td>\n",
       "      <td>0.284275</td>\n",
       "      <td>0.010297</td>\n",
       "      <td>0.002529</td>\n",
       "      <td>1.622711</td>\n",
       "      <td>-1.048298</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.067571</td>\n",
       "      <td>0.185870</td>\n",
       "      <td>0.010297</td>\n",
       "      <td>-0.019185</td>\n",
       "      <td>1.683568</td>\n",
       "      <td>-1.091187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.021796</td>\n",
       "      <td>-0.404558</td>\n",
       "      <td>0.010297</td>\n",
       "      <td>-0.048137</td>\n",
       "      <td>1.586197</td>\n",
       "      <td>-0.919631</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.021796</td>\n",
       "      <td>-0.699773</td>\n",
       "      <td>0.010297</td>\n",
       "      <td>-0.040899</td>\n",
       "      <td>1.403628</td>\n",
       "      <td>-0.533632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.021796</td>\n",
       "      <td>-0.109344</td>\n",
       "      <td>0.010297</td>\n",
       "      <td>-0.033661</td>\n",
       "      <td>1.148030</td>\n",
       "      <td>-0.190521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          F         D        R1        P0     TT_TU     RF_TU  P1  predict\n",
       "0  0.025015  0.284275  0.010297  0.002529  1.622711 -1.048298 NaN        1\n",
       "1  0.067571  0.185870  0.010297 -0.019185  1.683568 -1.091187 NaN        4\n",
       "2 -0.021796 -0.404558  0.010297 -0.048137  1.586197 -0.919631 NaN        4\n",
       "3 -0.021796 -0.699773  0.010297 -0.040899  1.403628 -0.533632 NaN        4\n",
       "4 -0.021796 -0.109344  0.010297 -0.033661  1.148030 -0.190521 NaN        1"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = softReg.predict(Xstan)\n",
    "dataStan['predict'] = yhat\n",
    "dataStan.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of Softmax permorfance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-269-2e7ba734f5ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataStan\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"P1\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myhat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# confusionMatrix = pd.DataFrame(data = cm, index=['poor(0), true','good(1), true','great(2), true'], columns = ['poor(0), predicted','good(1), predicted','great(2), predicted'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m     \"\"\"\n\u001b[1;32m--> 268\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\machinelearning\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \"\"\"\n\u001b[0;32m     80\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\machinelearning\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'f'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[1;31m# [.1, .2, 3] or [[.1, .2, 3]] or [[1., .2]] and not [1., 2., 3.]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m         \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    285\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m'continuous'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\machinelearning\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                     (type_err,\n\u001b[1;32m---> 60\u001b[1;33m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[0;32m     61\u001b[0m             )\n\u001b[0;32m     62\u001b[0m     \u001b[1;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(dataStan[\"P1\"].values, yhat)\n",
    "print(cm)\n",
    "\n",
    "# confusionMatrix = pd.DataFrame(data = cm, index=['poor(0), true','good(1), true','great(2), true'], columns = ['poor(0), predicted','good(1), predicted','great(2), predicted'])\n",
    "# confusionMatrix.loc['sum'] = confusionMatrix.sum()\n",
    "# confusionMatrix['sum'] = confusionMatrix.sum(axis=1)\n",
    "# confusionMatrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
