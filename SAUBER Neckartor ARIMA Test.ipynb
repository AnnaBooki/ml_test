{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import database setup\n",
    "import setup_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SARIMA example\n",
    "from statsmodels.tsa.ar_model import AR\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.ar_model import ARResults\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search sarima hyperparameters\n",
    "from math import sqrt\n",
    "from multiprocessing import cpu_count\n",
    "from joblib import Parallel\n",
    "from joblib import delayed\n",
    "from warnings import catch_warnings\n",
    "from warnings import filterwarnings\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = setup_env.get_database()\n",
    "print(engine)\n",
    "try:\n",
    "    con = engine.raw_connection()\n",
    "    con.cursor().execute(\"SET SCHEMA '{}'\".format(\"here_traffic\"))\n",
    "except:\n",
    "    print(\"Con: DB Verbindung prÃ¼fen!\") \n",
    "    exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = \"*\"\n",
    "sel_link_id = 563933733\n",
    "sel_min_confidence = 0\n",
    "sel_max_weekday = 5\n",
    "sel_func_classes = ('4','3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = f\"\"\"\n",
    "    SELECT DISTINCT tr.*  \n",
    "    FROM here_traffic.stuttgart_traffic tr\n",
    "    JOIN here_streets.fc_streets_all_2018q3 st on tr.link_id = st.link_id\n",
    "    WHERE tr.link_id = {sel_link_id}\n",
    "    AND tr.confidence > {sel_min_confidence}\n",
    "    AND tr.weekday_n < {sel_max_weekday}\n",
    "    --AND st.func_class in {sel_func_classes}\n",
    "    AND tr.dir_travel = 'F'\n",
    "    LIMIT 100000\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pd_read = pd.read_sql_query(sql_query, con)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    pd_read,\n",
    "    columns=[\n",
    "        \"id_pk\",        #0\n",
    "        \"link_id\",      #1\n",
    "        \"mean_kmh\",     #2\n",
    "        \"min_kmh\",      #3\n",
    "        \"max_kmh\",      #4\n",
    "        \"datum_zeit\",   #5\n",
    "        \"weekday_n\",    #6\n",
    "        \"epoch_60\",     #7\n",
    "        \"freeflow_kmh\",\n",
    "        \"confidence\",\n",
    "        \"count_n\"\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n",
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(df['count_n'], lags=72)\n",
    "\n",
    "plot_pacf(df['count_n'], lags=72)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = df['count_n'].diff(periods=1)\n",
    "df_diff.dropna(inplace=True)\n",
    "df_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_acf(df_diff, lags=72)\n",
    "\n",
    "plot_pacf(df_diff, lags=72)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "count_plt = sns.lineplot(data=df_diff[:144], legend=False)\n",
    "sns.set()\n",
    "plt.figure(figsize=(60,10))\n",
    "plt.savefig('imgs/lag_24.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('datum_zeit', inplace=True, drop=True)\n",
    "df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df[(df.index  > '2018-05-01 00:00:00') & (df.index < '2018-09-1 00:00:00')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.date_range(start = '2018-05-01 00:00:00', end = '2018-09-1 00:00:00' ).difference(df4.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.index.to_timestamp()\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "series = df['count_n']\n",
    "# split dataset\n",
    "X = series.values\n",
    "print(X)\n",
    "train, test = X[1:len(X)-48], X[len(X)-48:]\n",
    "# train autoregression\n",
    "model = SARIMAX(train)\n",
    "model_fit = model.fit()\n",
    "window = model_fit.k_ar\n",
    "coef = model_fit.params\n",
    "# walk forward over time steps in test\n",
    "history = train[len(train)-window:]\n",
    "history = [history[i] for i in range(len(history))]\n",
    "predictions = list()\n",
    "for t in range(len(test)):\n",
    "\tlength = len(history)\n",
    "\tlag = [history[i] for i in range(length-window,length)]\n",
    "\tyhat = coef[0]\n",
    "\tfor d in range(window):\n",
    "\t\tyhat += coef[d+1] * lag[window-d-1]\n",
    "\tobs = test[t]\n",
    "\tpredictions.append(yhat)\n",
    "\thistory.append(obs)\n",
    "\tprint('predicted=%f, expected=%f' % (yhat, obs))\n",
    "error = mean_squared_error(test, predictions)\n",
    "print('Test MSE: %.3f' % error)\n",
    "# plot\n",
    "plt.plot(test)\n",
    "plt.plot(predictions, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "series = df['count_n']\n",
    "# split dataset\n",
    "X = series.values\n",
    "print(X)\n",
    "train, test = X[1:len(X)-72], X[len(X)-72:]\n",
    "# train autoregression\n",
    "model = AR(train)\n",
    "model_fit = model.fit()\n",
    "window = model_fit.k_ar\n",
    "coef = model_fit.params\n",
    "# walk forward over time steps in test\n",
    "history = train[len(train)-window:]\n",
    "history = [history[i] for i in range(len(history))]\n",
    "predictions = list()\n",
    "for t in range(len(test)):\n",
    "\tlength = len(history)\n",
    "\tlag = [history[i] for i in range(length-window,length)]\n",
    "\tyhat = coef[0]\n",
    "\tfor d in range(window):\n",
    "\t\tyhat += coef[d+1] * lag[window-d-1]\n",
    "\tobs = test[t]\n",
    "\tpredictions.append(yhat)\n",
    "\thistory.append(obs)\n",
    "\tprint('predicted=%f, expected=%f' % (yhat, obs))\n",
    "error = mean_squared_error(test, predictions)\n",
    "print('Test MSE: %.3f' % error)\n",
    "# plot\n",
    "plt.plot(test)\n",
    "plt.plot(predictions, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = sm.tsa.statespace.SARIMAX(df4['count_n'], trend='n',  order=(1,0,0), seasonal_order=(1,1,0,24), simple_differencing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from pandas import read_csv\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def evaluate_arima_model(X, arima_order):\n",
    "\t# prepare training dataset\n",
    "\ttrain_size = int(len(X) * 0.66)\n",
    "\ttrain, test = X[0:train_size], X[train_size:]\n",
    "\thistory = [x for x in train]\n",
    "\tpredictions = list()\n",
    "\tfor t in range(len(test)):\n",
    "\t\tmodel = ARIMA(history, order=arima_order)\n",
    "\t\tmodel_fit = model.fit(disp=0)\n",
    "\t\tyhat = model_fit.forecast()[0]\n",
    "\t\tpredictions.append(yhat)\n",
    "\t\thistory.append(test[t])\n",
    "\terror = mean_squared_error(test, predictions)\n",
    "\treturn error\n",
    "\n",
    "# Evaluation von ARIMA params\n",
    "def evaluate_models(dataset, p_values, d_values, q_values):\n",
    "\tdataset = dataset.astype('float32')\n",
    "\tbest_score, best_cfg = float(\"inf\"), None\n",
    "\tfor p in p_values:\n",
    "\t\tfor d in d_values:\n",
    "\t\t\tfor q in q_values:\n",
    "\t\t\t\torder = (p,d,q)\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tmse = evaluate_arima_model(dataset, order)\n",
    "\t\t\t\t\tif mse < best_score:\n",
    "\t\t\t\t\t\tbest_score, best_cfg = mse, order\n",
    "\t\t\t\t\tprint('Model%s MSE=%.3f' % (order,mse))\n",
    "\t\t\t\texcept:\n",
    "\t\t\t\t\tcontinue\n",
    "\tprint('Min ARIMA%s MSE=%.3f' % (best_cfg, best_score))\n",
    "\n",
    "series = df4['count_n']\n",
    "# evaluate parameters\n",
    "p_values = [0, 1, 24]\n",
    "d_values = range(0, 3)\n",
    "q_values = range(0, 3)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "evaluate_models(series.values, p_values, d_values, q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
