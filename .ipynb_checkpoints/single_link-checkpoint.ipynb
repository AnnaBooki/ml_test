{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from tensorflow import keras\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "import numpy\n",
    "\n",
    "# date-time parsing function for loading the dataset\n",
    "def parser(x):\n",
    "\treturn datetime.strptime('190'+x, '%Y-%m')\n",
    "\n",
    "# frame a sequence as a supervised learning problem\n",
    "def timeseries_to_supervised(data, lag=1):\n",
    "\tdf = DataFrame(data)\n",
    "\tcolumns = [df.shift(i) for i in range(1, lag+1)]\n",
    "\tcolumns.append(df)\n",
    "\tdf = concat(columns, axis=1)\n",
    "\tdf.fillna(0, inplace=True)\n",
    "\treturn df\n",
    "\n",
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "\tdiff = list()\n",
    "\tfor i in range(interval, len(dataset)):\n",
    "\t\tvalue = dataset[i] - dataset[i - interval]\n",
    "\t\tdiff.append(value)\n",
    "\treturn Series(diff)\n",
    "\n",
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "\treturn yhat + history[-interval]\n",
    "\n",
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "\t# fit scaler\n",
    "\tscaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\tscaler = scaler.fit(train)\n",
    "\t# transform train\n",
    "\ttrain = train.reshape(train.shape[0], train.shape[1])\n",
    "\ttrain_scaled = scaler.transform(train)\n",
    "\t# transform test\n",
    "\ttest = test.reshape(test.shape[0], test.shape[1])\n",
    "\ttest_scaled = scaler.transform(test)\n",
    "\treturn scaler, train_scaled, test_scaled\n",
    "\n",
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, value):\n",
    "\tnew_row = [x for x in X] + [value]\n",
    "\tarray = numpy.array(new_row)\n",
    "\tarray = array.reshape(1, len(array))\n",
    "\tinverted = scaler.inverse_transform(array)\n",
    "\treturn inverted[0, -1]\n",
    "\n",
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "\tX, y = train[:, 0:-1], train[:, -1]\n",
    "\tX = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "\tmodel.add(Dense(1))\n",
    "\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\tfor i in range(nb_epoch):\n",
    "\t\tmodel.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
    "\t\tmodel.reset_states()\n",
    "\treturn model\n",
    "\n",
    "# make a one-step forecast\n",
    "def forecast_lstm(model, batch_size, X):\n",
    "\tX = X.reshape(1, 1, len(X))\n",
    "\tyhat = model.predict(X, batch_size=batch_size)\n",
    "\treturn yhat[0,0]\n",
    "\n",
    "dataset_path = keras.utils.get_file(\"shampoo-sales.csv\", \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/shampoo.csv\")\n",
    "dataset_path\n",
    "\n",
    "# load dataset\n",
    "series = read_csv(dataset_path, header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n",
    "\n",
    "# transform data to be stationary\n",
    "raw_values = series.values\n",
    "diff_values = difference(raw_values, 1)\n",
    "\n",
    "# transform data to be supervised learning\n",
    "supervised = timeseries_to_supervised(diff_values, 1)\n",
    "supervised_values = supervised.values\n",
    "\n",
    "# split data into train and test-sets\n",
    "train, test = supervised_values[0:-12], supervised_values[-12:]\n",
    "\n",
    "# transform the scale of the data\n",
    "scaler, train_scaled, test_scaled = scale(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass:  2\n",
      "Pass:  3\n",
      "Pass:  4\n",
      "Pass:  5\n",
      "Pass:  6\n",
      "Pass:  7\n",
      "Pass:  8\n",
      "Pass:  9\n",
      "Pass:  10\n",
      "Pass:  11\n",
      "Pass:  12\n",
      "Pass:  13\n",
      "Pass:  14\n",
      "Pass:  15\n",
      "Pass:  16\n",
      "Pass:  17\n",
      "Pass:  18\n",
      "Pass:  19\n",
      "Pass:  20\n",
      "Pass:  21\n",
      "Pass:  22\n",
      "Pass:  23\n",
      "Pass:  24\n",
      "Pass:  25\n",
      "Pass:  26\n",
      "Pass:  27\n",
      "Pass:  28\n",
      "Pass:  29\n",
      "Pass:  30\n",
      "Pass:  31\n"
     ]
    }
   ],
   "source": [
    "#Experiment wiederholen\n",
    "repeats = 30\n",
    "i = 1\n",
    "error_scores = list()\n",
    "for r in range(repeats):\n",
    "    i += 1\n",
    "    print(\"Pass: \",i)\n",
    "    # fit the model\n",
    "    lstm_model = fit_lstm(train_scaled, 1, 3000, 4)\n",
    "    # forecast the entire training dataset to build up state for forecasting\n",
    "    train_reshaped = train_scaled[:, 0].reshape(len(train_scaled), 1, 1)\n",
    "    lstm_model.predict(train_reshaped, batch_size=1)\n",
    "    predictions = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30) Test RMSE: 6.400\n"
     ]
    }
   ],
   "source": [
    "\tfor i in range(len(test_scaled)):\n",
    "\t\tX, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
    "\t\tyhat = forecast_lstm(lstm_model, 1, X)\n",
    "\t\tyhat = invert_scale(scaler, X, yhat)\n",
    "\t\tyhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "\t\tpredictions.append(yhat)\n",
    "\trmse = sqrt(mean_squared_error(raw_values[-12:], predictions))/30\n",
    "\tprint('%d) Test RMSE: %.3f' % (r+1, rmse))\n",
    "\terror_scores.append(rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           rmse\n",
      "count  1.000000\n",
      "mean   6.399528\n",
      "std         NaN\n",
      "min    6.399528\n",
      "25%    6.399528\n",
      "50%    6.399528\n",
      "75%    6.399528\n",
      "max    6.399528\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Zsmfsn\n",
    "results = DataFrame()\n",
    "results['rmse'] = error_scores\n",
    "print(results.describe())\n",
    "results.boxplot()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
